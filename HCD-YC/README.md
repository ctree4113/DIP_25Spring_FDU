# Learning Hazing to Dehazing: Towards Realistic Haze Generation for Real-World Image Dehazing [:link:](https://arxiv.org/abs/2503.19262)

![Python 3.10](https://img.shields.io/badge/python-3.10-g) ![pytorch 2.2.2](https://img.shields.io/badge/pytorch-2.2.2-blue.svg)

This repository presents the implementation of the paper

>**Learning Hazing to Dehazing: Towards Realistic Haze Generation for Real-World Image Dehazing**<br> Ruiyi Wang, Yushuo Zheng, Zicheng Zhang, Chunyi Li, Shuaicheng Liu, Guangtao Zhai, Xiaohong Liu<br>The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR), 2025

We present a novel hazing-dehazing pipeline consisting of a Realistic Hazy Image Generation framework (HazeGen) and a Diffusion-based Dehazing framework (DiffDehaze).

![teaser](assets/teaser.png)
![teaser](assets/result.png)

## ğŸ› ï¸ Setup

### ğŸ“¦ Repository

Clone the repository (requires git):

```bash
git clone https://github.com/ruiyi-w/Learning-Hazing-to-Dehazing.git
cd Learning-Hazing-to-Dehazing
```

### ğŸ’» Dependencies
Using [Conda](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html). After the installation, create the environment and install dependencies into it:

```bash
conda create -n env_name python=3.10
conda activate env_name
pip install -r requirements.txt
```

Keep the environment activated before running the inference script. 
Activate the environment again after restarting the terminal session.

## ğŸƒ Testing

### ğŸ“· Prepare input images

Place your images in the `inputs/` directory. To set a different source directory, you can edit configuration files in `configs/inference/`.

### â¬‡ Download Checkpoints

Download pre-trained models and place them to folder `weights/`, but you can always edit configuration files in `configs/inference/`.

|        Model Name        |                         Description                          |                             Link                             |
| :----------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| v2-1_512-ema-pruned.ckpt | Pretrained Stable Diffusion v2.1 from stabilityai, providing generative priors | [download](https://huggingface.co/stabilityai/stable-diffusion-2-1-base) |
|        stage1.pt         |               IRControlNet trained for HazeGen               | [download](https://pan.baidu.com/s/1vbxEwftJC9nUaMXJ-t9sww?pwd=8egg) |
|        stage2.pt         |             IRControlNet trained for DiffDehaze              | [download](https://pan.baidu.com/s/1vbxEwftJC9nUaMXJ-t9sww?pwd=8egg) |

### ğŸš€ Run inference

To perform dehazing with standard spaced sampler, please run

```bash
python inference_stage2.py --config configs/inference/stage2.yaml
```

By default, results will be saved to `outputs/`. **Enjoy**!

To perform dehazing with AccSamp sampler, please run

```bash
python inference_accsamp.py --config configs/inference/stage2_accsamp.yaml
```

To generate realisitic hazy images with HazeGen, please run

```bash
python inference_stage1.py --config configs/inference/stage1.yaml
```

To use a different hyperparameter settings, e.g., $\tau$ and $\omega$, please edit the corresponding `.yaml` configuration file.

## ğŸ‹ï¸ Training

1. Training data preparation. 
   - The training of HazeGen requires real-world hazy data from the URHI split of [RESIDE](https://sites.google.com/view/reside-dehaze-datasets/reside-Î²) dataset and the synthetic hazy data from [RIDCP](https://github.com/RQ-Wu/RIDCP_dehazing). 
   - To train DiffDehaze, you need to generate realistic hazy data from HazeGen based on clean images, e.g., the clean images from the OTS split of [RESIDE](https://sites.google.com/view/reside-dehaze-datasets/reside-Î²) dataset, using the inference script above.

2. Accelerate configuration. The training is supported by the huggingface [Accelerate](https://huggingface.co/docs/transformers/accelerate) library. Before running training scripts, create and save a configuration file to help Accelerate correctly set up training based on your setup by running 

```bash
accelerate config
```

3. Fill in the training configuration files in `configs/train/` with appropriate values, especially for the paths to the training data. Please find specific instructions there.
4. Start training! To train stage1 HazeGen model, run

```bash
accelerate launch train_stage1.py --config configs/train/stage1.yaml
```

5. To train stage2 DiffDehaze model, run

```bash
accelerate launch train_stage2.py --config configs/train/stage2.yaml
```

## âœï¸ Acknowledgment

A large part of the implementation is based on [DiffBIR](https://github.com/XPixelGroup/DiffBIR?tab=readme-ov-file#inference). We sincerely appreciate their wonderful work.

## ğŸ“ Citation

If you find our work useful, please consider cite our paper:

```bibtex
@misc{wang2025learninghazingdehazingrealistic,
      title={Learning Hazing to Dehazing: Towards Realistic Haze Generation for Real-World Image Dehazing}, 
      author={Ruiyi Wang and Yushuo Zheng and Zicheng Zhang and Chunyi Li and Shuaicheng Liu and Guangtao Zhai and Xiaohong Liu},
      year={2025},
      eprint={2503.19262},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.19262}, 
}
```

## ğŸ« License

This work is licensed under the Apache License, Version 2.0 (as defined in the [LICENSE](LICENSE.txt)).

By downloading and using the code and models you agree to the terms in the  [LICENSE](LICENSE.txt).

[![License](https://img.shields.io/badge/License-Apache--2.0-929292)](https://www.apache.org/licenses/LICENSE-2.0)

# HCD-YCï¼šå±‚çº§å¾ªç¯ä¸€è‡´çš„YCbCrè¾…åŠ©å»é›¾æ¡†æ¶

æˆ‘ä»¬åŸºäº"Learning Hazing to Dehazing"åŸå§‹æ¡†æ¶è¿›è¡Œäº†ä¸‰é¡¹é‡è¦åˆ›æ–°ï¼Œå½¢æˆäº†HCD-YCæ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†å»é›¾æ•ˆæœå’ŒçœŸå®æ„Ÿã€‚HCD-YCä¿ç•™äº†åŒé˜¶æ®µè®¾è®¡ï¼ˆé›¾æ°”ç”Ÿæˆ+é›¾æ°”å»é™¤ï¼‰ï¼ŒåŒæ—¶åœ¨æ¯ä¸ªé˜¶æ®µå¼•å…¥äº†åˆ›æ–°æ€§çš„æ”¹è¿›ã€‚

## æ•´ä½“æ¶æ„

HCD-YCæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š

1. **YC-HazeGen**ï¼šé›¾æ°”ç”Ÿæˆé˜¶æ®µï¼Œä»æ¸…æ™°å›¾åƒç”ŸæˆçœŸå®é›¾å›¾
   - ä½¿ç”¨YCbCrè‰²å½©ç©ºé—´è¾…åŠ©å¤„ç†
   - åº”ç”¨å±‚çº§å¾ªç¯ä¸€è‡´æ€§çº¦æŸ

2. **YC-DiffDehaze**ï¼šå»é›¾é˜¶æ®µï¼Œä»é›¾å›¾è¿˜åŸæ¸…æ™°å›¾åƒ
   - é‡‡ç”¨YCbCrè‰²å½©ç©ºé—´å¤šç‰¹å¾èåˆ
   - åˆ©ç”¨å±‚çº§å¾ªç¯ä¸€è‡´æ€§å­¦ä¹ 
   - ä½¿ç”¨ä¼˜åŒ–çš„æ–‡æœ¬å¼•å¯¼æ§åˆ¶

## YCbCrè‰²å½©ç©ºé—´è¾…åŠ©å»é›¾

æˆ‘ä»¬å¯¹åŸå§‹æ¨¡å‹è¿›è¡Œäº†å¢å¼ºï¼Œå¼•å…¥äº†YCbCrè‰²å½©ç©ºé—´å¤„ç†æ¨¡å—ï¼Œä»¥æé«˜å»é›¾æ•ˆæœï¼Œç‰¹åˆ«æ˜¯åœ¨ä¿ç•™å›¾åƒç»†èŠ‚å’Œå¤„ç†å¤æ‚åœºæ™¯æ–¹é¢ã€‚

### ä¸»è¦æ”¹è¿›

1. **åŒè‰²å½©ç©ºé—´å¤„ç†**ï¼šåŒæ—¶åœ¨RGBå’ŒYCbCrè‰²å½©ç©ºé—´ä¸­æå–å’Œå¤„ç†ç‰¹å¾ï¼Œå……åˆ†åˆ©ç”¨YCbCrç©ºé—´å¯¹ç»“æ„å’Œçº¹ç†çš„æ›´å¥½è¡¨ç¤ºèƒ½åŠ›ã€‚

2. **ç‰¹å¾èåˆæœºåˆ¶**ï¼šè®¾è®¡äº†åŸºäºæ³¨æ„åŠ›çš„ç‰¹å¾èåˆæ¨¡å—ï¼Œæœ‰æ•ˆæ•´åˆRGBå’ŒYCbCrç©ºé—´çš„ä¼˜åŠ¿ï¼Œæå‡å»é›¾æ•ˆæœã€‚

3. **å¤šå±‚çº§ç‰¹å¾äº¤äº’**ï¼šåœ¨ç½‘ç»œçš„å¤šä¸ªå±‚çº§å®ç°RGBå’ŒYCbCrç‰¹å¾çš„äº¤äº’ï¼Œç¡®ä¿å…¨é¢çš„ä¿¡æ¯èåˆã€‚

### ä½¿ç”¨æ–¹æ³•

è¦å¯ç”¨YCbCrè‰²å½©ç©ºé—´å¤„ç†ï¼Œè¯·ä½¿ç”¨ä¿®æ”¹åçš„é…ç½®æ–‡ä»¶ï¼š

```bash
# è®­ç»ƒç¬¬ä¸€é˜¶æ®µ
python train_stage1.py --config configs/train/stage1.yaml

# è®­ç»ƒç¬¬äºŒé˜¶æ®µ
python train_stage2.py --config configs/train/stage2.yaml
```

### å®éªŒç»“æœ

YCbCrè‰²å½©ç©ºé—´è¾…åŠ©å¤„ç†åœ¨ä»¥ä¸‹æ–¹é¢æä¾›äº†æ”¹è¿›ï¼š

- æ›´å¥½çš„ç»†èŠ‚ä¿ç•™ï¼Œç‰¹åˆ«æ˜¯åœ¨çº¹ç†ä¸°å¯Œçš„åŒºåŸŸ
- æ”¹å–„äº†è‰²å½©è¿˜åŸè´¨é‡ï¼Œå‡å°‘äº†å»é›¾è¿‡ç¨‹ä¸­çš„è‰²å
- åœ¨éå‡åŒ€é›¾æ°”åœºæ™¯ä¸­å±•ç°å‡ºæ›´å¼ºçš„å»é›¾èƒ½åŠ›

## å±‚çº§å¾ªç¯ä¸€è‡´æ€§å­¦ä¹ 

æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„å±‚çº§å¾ªç¯ä¸€è‡´æ€§å­¦ä¹ æ¡†æ¶ï¼Œåœ¨å¤šä¸ªç‰¹å¾å±‚çº§ä¸Šå¼ºåŒ–å»é›¾æ¨¡å‹çš„ä¸€è‡´æ€§ï¼Œå¤§å¹…æå‡ç»“æœçš„è‡ªç„¶åº¦å’ŒçœŸå®æ„Ÿã€‚

### ä¸»è¦æ”¹è¿›

1. **å¤šå±‚çº§ä¸€è‡´æ€§çº¦æŸ**ï¼šå°†å¾ªç¯ä¸€è‡´æ€§æ‰©å±•åˆ°ä¸‰ä¸ªä¸åŒå±‚çº§ï¼š
   - åƒç´ çº§ä¸€è‡´æ€§ï¼šç¡®ä¿åŸºæœ¬è‰²å½©å’Œäº®åº¦çš„å‡†ç¡®æ¢å¤
   - ç‰¹å¾çº§ä¸€è‡´æ€§ï¼šé€šè¿‡VGGç‰¹å¾ä¿è¯çº¹ç†å’Œä¸­ç­‰å°ºåº¦ç»“æ„çš„ä¸€è‡´æ€§
   - è¯­ä¹‰çº§ä¸€è‡´æ€§ï¼šåˆ©ç”¨é«˜çº§ç‰¹å¾ç¡®ä¿è¯­ä¹‰ä¿¡æ¯å’Œå¤§å°ºåº¦ç»“æ„çš„ä¿æŒ

2. **è‡ªé€‚åº”æƒé‡è°ƒæ•´**ï¼šæ ¹æ®é›¾æ°”å¯†åº¦åŠ¨æ€è°ƒæ•´ä¸åŒå±‚çº§æŸå¤±çš„æƒé‡ï¼Œå¯¹ä¸åŒåœºæ™¯é€‚åº”æ€§æ›´å¼º

3. **åŒºåŸŸæ„ŸçŸ¥å¾ªç¯ä¸€è‡´æ€§**ï¼šé’ˆå¯¹ä¸åŒå›¾åƒåŒºåŸŸï¼ˆå¦‚å¤©ç©ºã€å»ºç­‘ç‰©ç­‰ï¼‰é‡‡ç”¨ä¸åŒçš„ä¸€è‡´æ€§çº¦æŸï¼Œæé«˜ç»†èŠ‚ä¿ç•™

4. **éå¯¹ç§°å¾ªç¯å­¦ä¹ **ï¼šè€ƒè™‘åˆ°é›¾åŒ–å’Œå»é›¾è¿‡ç¨‹çš„ä¸å¯¹ç§°æ€§ï¼Œè®¾è®¡äº†æƒé‡ä¸åŒçš„åŒå‘ä¸€è‡´æ€§æŸå¤±

### ä½¿ç”¨æ–¹æ³•

è¦å¯ç”¨å±‚çº§å¾ªç¯ä¸€è‡´æ€§å­¦ä¹ ï¼Œç¡®ä¿åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ç›¸å…³å‚æ•°ï¼š

```bash
# ä¾‹å¦‚å¯ç”¨é˜¶æ®µä¸€çš„å¾ªç¯ä¸€è‡´æ€§è®­ç»ƒ
accelerate launch train_stage1.py --config configs/train/stage1.yaml
```

### å®éªŒç»“æœ

å±‚çº§å¾ªç¯ä¸€è‡´æ€§å­¦ä¹ å¸¦æ¥çš„æ˜¾è‘—æ”¹è¿›ï¼š

- æ›´è‡ªç„¶çš„ç»†èŠ‚æ¢å¤ï¼Œå‡å°‘è¿‡åº¦å¹³æ»‘å’Œä¼ªå½±
- ä¿æŒäº†åŸå§‹å›¾åƒçš„è¯­ä¹‰ä¿¡æ¯å’Œå…¨å±€ç»“æ„
- æœ‰æ•ˆé¿å…äº†å¸¸è§çš„è‰²åå’Œä¼ªå½©é—®é¢˜
- åœ¨å¤æ‚çœŸå®åœºæ™¯ä¸­å±•ç°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›

## ä¼˜åŒ–çš„æ–‡æœ¬å¼•å¯¼æ§åˆ¶

æˆ‘ä»¬å¯¹æ–‡æœ¬å¼•å¯¼æœºåˆ¶è¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–ï¼Œå¢å¼ºäº†æ¨¡å‹æ ¹æ®é›¾å›¾ç‰¹æ€§åŠ¨æ€é€‰æ‹©å’Œä¼˜åŒ–æ–‡æœ¬æç¤ºçš„èƒ½åŠ›ï¼Œæé«˜äº†å»é›¾çš„ç²¾ç¡®åº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚

### ä¸»è¦æ”¹è¿›

1. **åŠ¨æ€æ–‡æœ¬æç¤ºæ± **ï¼šå»ºç«‹äº†åˆ†å±‚çš„æ–‡æœ¬æç¤ºåº“ï¼Œèƒ½æ ¹æ®ä¸åŒé›¾æ°”å¯†åº¦ï¼ˆè½»åº¦ã€ä¸­åº¦ã€é‡åº¦ï¼‰ã€é›¾æ°”ç±»å‹ï¼ˆå‡åŒ€ã€åˆ†å±‚ã€éå‡åŒ€ï¼‰å’Œåœºæ™¯ç±»å‹ï¼ˆåŸå¸‚ã€è‡ªç„¶ã€å®¤å†…ï¼‰æä¾›ç²¾ç¡®æè¿°ã€‚

2. **æ™ºèƒ½é›¾æ°”åˆ†æå™¨**ï¼šè®¾è®¡äº†ä¸“é—¨çš„é›¾æ°”åˆ†ææ¨¡å—ï¼Œèƒ½è‡ªåŠ¨è¯„ä¼°è¾“å…¥å›¾åƒçš„é›¾æ°”ç‰¹æ€§ï¼ŒåŒ…æ‹¬ï¼š
   - å¯†åº¦ä¼°è®¡ï¼šé€šè¿‡äº®åº¦å’Œæ–¹å·®åˆ†æ
   - ç±»å‹åˆ¤æ–­ï¼šé€šè¿‡æ¢¯åº¦å’Œçº¹ç†ç‰¹å¾
   - åœºæ™¯è¯†åˆ«ï¼šåŸºäºé¢œè‰²åˆ†å¸ƒå’Œè¾¹ç¼˜å¯†åº¦

3. **æ–‡æœ¬æ¡ä»¶åµŒå…¥ä¼˜åŒ–**ï¼šå®ç°äº†ä¸“é—¨çš„æ–‡æœ¬æ¡ä»¶å¤„ç†å™¨ï¼Œé€šè¿‡ä¸¤ä¸ªå…³é”®æœºåˆ¶ä¼˜åŒ–æ–‡æœ¬åµŒå…¥ï¼š
   - å¢å¼ºå±‚ï¼šæå‡æ–‡æœ¬ç‰¹å¾çš„è¡¨è¾¾èƒ½åŠ›
   - è°ƒåˆ¶å±‚ï¼šåŠ¨æ€è°ƒæ•´æ–‡æœ¬å¼•å¯¼çš„å½±å“ç¨‹åº¦

4. **æ–‡æœ¬-å›¾åƒå¯¹é½æŸå¤±**ï¼šåˆ›æ–°æ€§å¼•å…¥äº†æ–‡æœ¬ä¸å›¾åƒç‰¹å¾çš„å¯¹é½æœºåˆ¶ï¼Œç¡®ä¿å»é›¾ç»“æœä¸æ–‡æœ¬æè¿°åœ¨è¯­ä¹‰ä¸Šä¿æŒä¸€è‡´ã€‚

### ä½¿ç”¨æ–¹æ³•

æ–‡æœ¬å¼•å¯¼æ§åˆ¶å·²åœ¨æ¨ç†å’Œè®­ç»ƒè„šæœ¬ä¸­å®Œå…¨é›†æˆï¼Œå¯é€šè¿‡é…ç½®æ–‡ä»¶æ§åˆ¶å…¶è¡Œä¸ºï¼š

```yaml
# åœ¨æ¨ç†é…ç½®ä¸­å¯ç”¨åŠ¨æ€æ–‡æœ¬æç¤ºå’Œæ–‡æœ¬å¤„ç†
inference:
  use_dynamic_prompt: True  # æ˜¯å¦ä½¿ç”¨åŠ¨æ€æ–‡æœ¬æç¤º
  use_text_processor: True  # æ˜¯å¦ä½¿ç”¨æ–‡æœ¬æ¡ä»¶ä¼˜åŒ–å¤„ç†

# åœ¨è®­ç»ƒé…ç½®ä¸­è®¾ç½®è¯¦ç»†å‚æ•°
train:
  use_dynamic_prompt: True    # å¯ç”¨åŠ¨æ€æç¤ºè¯é€‰æ‹©
  dynamic_prompt_start: 2000  # å¼€å§‹ä½¿ç”¨åŠ¨æ€æç¤ºè¯çš„æ­¥æ•°
  use_text_processor: True    # å¯ç”¨æ–‡æœ¬æ¡ä»¶ä¼˜åŒ–å¤„ç†
  text_processor_start: 2000  # å¼€å§‹ä½¿ç”¨å¤„ç†å™¨çš„æ­¥æ•°
  text_align_weight: 0.3      # æ–‡æœ¬-å›¾åƒå¯¹é½æŸå¤±æƒé‡
  text_align_max_step: 3000   # å¯¹é½æŸå¤±è¾¾åˆ°æœ€å¤§æƒé‡çš„æ­¥æ•°
```

### å®éªŒç»“æœ

ä¼˜åŒ–çš„æ–‡æœ¬å¼•å¯¼æ§åˆ¶å¸¦æ¥çš„æ˜¾è‘—æ”¹è¿›ï¼š

- æ›´ç²¾ç¡®çš„å»é›¾æ•ˆæœï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ä¸åŒç±»å‹çš„é›¾æ°”åœºæ™¯
- æé«˜äº†è¯­ä¹‰ä¸€è‡´æ€§ï¼Œç”Ÿæˆçš„ç»“æœæ›´ç¬¦åˆæè¿°æ„å›¾
- å¢å¼ºäº†æ¨¡å‹å¯¹å¤æ‚çœŸå®åœºæ™¯çš„é€‚åº”èƒ½åŠ›
- å‡å°‘äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸ç¨³å®šæ€§ï¼ŒåŠ é€Ÿäº†æ”¶æ•›

## è®­ç»ƒä¸æ¨ç†

### è®­ç»ƒæ–¹æ³•

å®Œæ•´çš„è®­ç»ƒæµç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼š

1. **è®­ç»ƒç¬¬ä¸€é˜¶æ®µ (YC-HazeGen)**ï¼š

```bash
# åŸºç¡€è®­ç»ƒå‘½ä»¤
accelerate launch train_stage1.py --config configs/train/stage1.yaml

# å¤šGPUè®­ç»ƒ (ä¾‹å¦‚ä½¿ç”¨4ä¸ªGPU)
CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --multi_gpu train_stage1.py --config configs/train/stage1.yaml
```

2. **è®­ç»ƒç¬¬äºŒé˜¶æ®µ (YC-DiffDehaze)**ï¼š

```bash
# åŸºç¡€è®­ç»ƒå‘½ä»¤
accelerate launch train_stage2.py --config configs/train/stage2.yaml

# å¤šGPUè®­ç»ƒ
CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch --multi_gpu train_stage2.py --config configs/train/stage2.yaml
```

### æ¨ç†æ–¹æ³•

æˆ‘ä»¬æä¾›å¤šç§æ¨ç†é€‰é¡¹ï¼Œé€‚åº”ä¸åŒéœ€æ±‚ï¼š

1. **æ ‡å‡†å»é›¾æ¨ç†**ï¼š

```bash
python inference_stage2.py --config configs/inference/stage2.yaml
```

2. **ä½¿ç”¨åŠ é€Ÿé‡‡æ ·è¿›è¡Œå»é›¾**ï¼š

```bash
python inference_accsamp.py --config configs/inference/stage2_accsamp.yaml
```

3. **é›¾åŒ–å›¾åƒç”Ÿæˆ**ï¼š

```bash
python inference_stage1.py --config configs/inference/stage1.yaml
```

### å‚æ•°é…ç½®

é€šè¿‡ä¿®æ”¹é…ç½®æ–‡ä»¶å¯ä»¥æ§åˆ¶å„ç§åŠŸèƒ½å’Œå‚æ•°ï¼š

- **YCbCrè‰²å½©ç©ºé—´**ï¼šé€šè¿‡`ycbcr_fusion: True`æ§åˆ¶
- **å±‚çº§å¾ªç¯ä¸€è‡´æ€§**ï¼šé€šè¿‡`cycle_weight`, `pixel_weight`, `feature_weight`ç­‰å‚æ•°æ§åˆ¶
- **æ–‡æœ¬å¼•å¯¼æ§åˆ¶**ï¼šé€šè¿‡`use_dynamic_prompt`, `text_align_weight`ç­‰å‚æ•°æ§åˆ¶

### å®éªŒè¯„ä¼°

æˆ‘ä»¬åœ¨æ ‡å‡†æ•°æ®é›†å’ŒçœŸå®åœºæ™¯å›¾åƒä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼š

- **å®šé‡æŒ‡æ ‡**ï¼šPSNR, SSIM, CIEDE2000ç­‰
- **æ— å‚è€ƒæŒ‡æ ‡**ï¼šNIQE, BRISQUE
- **ä¸»è§‚è¯„ä»·**ï¼šæ¸…æ™°åº¦, è‡ªç„¶åº¦, ç»†èŠ‚ä¿ç•™ç¨‹åº¦

æ‰€æœ‰ä¸‰é¡¹åˆ›æ–°éƒ½æ˜¾è‘—æå‡äº†å»é›¾æ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤„ç†å¤æ‚çœŸå®åœºæ™¯å’Œéå‡åŒ€é›¾æ°”æ—¶æ•ˆæœæ˜¾è‘—ã€‚
