\relax 
\citation{mccartney1976optics}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\citation{wang2025learning}
\citation{he2010single}
\citation{zhu2015fast}
\citation{cai2016dehazenet}
\citation{li2017aod}
\citation{dong2020multi}
\citation{qin2020ffa}
\citation{lin2023diffbir}
\citation{wang2025learning}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Traditional Image Dehazing}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Deep Learning-Based Dehazing}{2}{}\protected@file@percent }
\citation{fang2025guided}
\citation{wang2025learning}
\citation{zhang2023iterative}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overall framework of our HCD-YC method. The pipeline consists of YCbCr-assisted dual-branch processing, hierarchical cycle-consistency learning with adaptive weighting, refined text guidance with dynamic prompt selection, and ISR-AlignOp for iterative statistical refinement. The framework leverages both RGB and YCbCr color spaces to achieve superior dehazing performance.\relax }}{3}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:framework}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Diffusion-Based Image Restoration}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Color Space Processing in Computer Vision}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Sampling-Based Dehazing and Statistical Alignment}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}YCbCr-Assisted Haze Representation}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Color Space Conversion and Processing}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Dual-Branch Architecture and Feature Fusion}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Hierarchical Cycle-Consistency Learning}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Multi-Level Consistency Framework}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Adaptive Weighting and Region-Aware Processing}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Refined Text Guidance}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Dynamic Prompt Selection System}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Enhanced Text-Image Alignment}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}ISR-AlignOp}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Motivation and Problem Analysis}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Architecture of ISR-AlignOp mechanism. The framework employs two-step iterative refinement using early diffusion predictions at strategic time points $\tau _a$ and $\tau _b$. The first step applies AlignOp between the hazy image and prediction $P_a$, followed by a second refinement step using prediction $P_b$ to generate the final estimate.\relax }}{7}{}\protected@file@percent }
\newlabel{fig:isr_alignop}{{2}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Two-Step Iterative Refinement Framework}{7}{}\protected@file@percent }
\newlabel{eq:isr_step1}{{25}{7}}
\newlabel{eq:isr_step2}{{26}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Multi-Mode ISR Implementation}{7}{}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces AccSamp with ISR-AlignOp Enhancement\relax }}{8}{}\protected@file@percent }
\newlabel{alg:isr_accsamp}{{1}{8}}
\newlabel{eq:pred_diff}{{28}{8}}
\newlabel{eq:adaptive_decision}{{29}{8}}
\newlabel{eq:multiscale_isr}{{30}{8}}
\newlabel{eq:scale_weight}{{31}{8}}
\newlabel{eq:multiscale_fusion}{{32}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.4}Integration with AccSamp}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.5}Computational Complexity Analysis}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Experimental Setup}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Quantitative Results}{9}{}\protected@file@percent }
\citation{shao2020domain}
\citation{chen2021psd}
\citation{yang2022self}
\citation{wu2023ridcp}
\citation{wang2025learning}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Quantitative comparison of various dehazing methods on RTTS dataset. \textbf  {Bold} numbers indicate best performance. *Results obtained from checkpoints trained for 20,000 steps with batch size 24 (preliminary results from incomplete training).\relax }}{10}{}\protected@file@percent }
\newlabel{tab:quantitative_comparison}{{1}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}ISR-AlignOp Analysis}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Visual Quality Analysis}{10}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Visual comparison of dehazing results. Our HCD-YC method demonstrates superior haze removal while preserving fine details and natural color reproduction compared to the Learning H2D baseline. The results show enhanced clarity, improved contrast, and better structural preservation across diverse atmospheric conditions.\relax }}{11}{}\protected@file@percent }
\newlabel{fig:visual_comparison_1}{{3}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{11}{}\protected@file@percent }
\bibdata{references}
\bibcite{cai2016dehazenet}{{1}{2016}{{Cai et~al.}}{{Cai, Xu, Jia, Qing, and Tao}}}
\bibcite{chen2021psd}{{2}{2021}{{Chen et~al.}}{{Chen, Wang, Yang, and Liu}}}
\bibcite{dong2020multi}{{3}{2020}{{Dong et~al.}}{{Dong, Pan, Xiang, Hu, Zhang, Wang, and Yang}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Additional visual comparison results showing the effectiveness of our method across different haze densities and scene types. Our HCD-YC method consistently produces clearer results with better color fidelity and detail preservation compared to the baseline approach.\relax }}{12}{}\protected@file@percent }
\newlabel{fig:visual_comparison_2}{{4}{12}}
\bibcite{fang2025guided}{{4}{2025}{{Fang et~al.}}{{Fang, Fan, Zheng, Weng, Tai, and Li}}}
\bibcite{he2010single}{{5}{2010}{{He et~al.}}{{He, Sun, and Tang}}}
\bibcite{li2017aod}{{6}{2017}{{Li et~al.}}{{Li, Peng, Wang, Xu, and Feng}}}
\bibcite{lin2023diffbir}{{7}{2023}{{Lin et~al.}}{{Lin, Chen, Zhang, Dong, Wen, and Yuan}}}
\bibcite{mccartney1976optics}{{8}{1976}{{McCartney}}{{}}}
\bibcite{qin2020ffa}{{9}{2020}{{Qin et~al.}}{{Qin, Wang, Bai, Xie, and Jia}}}
\bibcite{shao2020domain}{{10}{2020}{{Shao et~al.}}{{Shao, Li, Ren, Gao, and Sang}}}
\bibcite{wang2025learning}{{11}{2025}{{Wang et~al.}}{{Wang, Zheng, Zhang, Li, Liu, Zhai, and Liu}}}
\bibcite{wu2023ridcp}{{12}{2023}{{Wu et~al.}}{{Wu, Duan, Guo, Chai, and Li}}}
\bibcite{yang2022self}{{13}{2022}{{Yang et~al.}}{{Yang, Wang, Liu, Zhang, Guo, and Tao}}}
\bibcite{zhang2023iterative}{{14}{2023}{{Zhang et~al.}}{{Zhang, Li, Liang, Cao, Zhang, Tang, Fan, Timofte, and Van~Gool}}}
\bibcite{zhu2015fast}{{15}{2015}{{Zhu et~al.}}{{Zhu, Mai, and Shao}}}
\bibstyle{abbrvnat}
\gdef \@abspage@last{13}
